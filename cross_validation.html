<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Cross Validation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" />
<script defer src="https://use.fontawesome.com/releases/v5.0.3/js/all.js"></script>
<script defer src="https://use.fontawesome.com/releases/v5.0.0/js/v4-shims.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-151578452-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-151578452-1');
</script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">P8105</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="schedule.html">Schedule</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="topic_what_is_data_science.html">What is Data Science?</a>
    </li>
    <li>
      <a href="topic_building_blocks.html">Building Blocks</a>
    </li>
    <li>
      <a href="topic_data_wrangling_i.html">Data Wrangling I</a>
    </li>
    <li>
      <a href="topic_visualization_and_eda.html">Visualization and EDA</a>
    </li>
    <li>
      <a href="topic_data_wrangling_ii.html">Data Wrangling II</a>
    </li>
    <li>
      <a href="topic_interactivity.html">Interactivity</a>
    </li>
    <li>
      <a href="topic_iteration.html">Iteration</a>
    </li>
    <li>
      <a href="topic_linear_models.html">Linear Models</a>
    </li>
    <li>
      <a href="topic_other_material.html">Other Materials</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Datasets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="dataset_airbnb.html">Airbnb</a>
    </li>
    <li>
      <a href="dataset_brfss.html">BRFSS</a>
    </li>
    <li>
      <a href="dataset_fivethirtyeight.html">FiveThirtyEight</a>
    </li>
    <li>
      <a href="dataset_instacart.html">Instacart</a>
    </li>
    <li>
      <a href="dataset_mr_trash_wheel.html">Mr. Trash Wheel</a>
    </li>
    <li>
      <a href="dataset_noaa.html">NOAA</a>
    </li>
    <li>
      <a href="dataset_restaurant_inspections.html">NYC Restaurant Inspections</a>
    </li>
  </ul>
</li>
<li>
  <a href="homework_and_projects.html">Homework and Projects</a>
</li>
<li>
  <a href="course_communication.html">Communication</a>
</li>
<li>
  <a href="https://github.com/P8105/p8105.github.io">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Cross Validation</h1>

</div>


<p>Although hypothesis tests provide a way to compare nested linear models, in many situations the approaches under consideration don’t fit nicely in this paradigm. Indeed, for many modern tools and in many applications, the emphasis lies on prediction accuracy rather than on statistical significance. In these cases, cross validation provides a way to compare the predictive performance of competing methods.</p>
<p>This is the second module in the <a href="topic_iteration.html">Linear Models</a> topic.</p>
<div id="overview" class="section level2 tabset tabset-pills">
<h2>Overview</h2>
<div id="learning-objectives" class="section level3">
<h3>Learning Objectives</h3>
<p>Implement cross validation to assess the predictive value of a model using tools for iteration.</p>
</div>
<div id="slide-deck" class="section level3">
<h3>Slide Deck</h3>
<div class="vid_container">
<p><iframe 
    src="https://speakerdeck.com/player/3d0f3a0545fb422ba6ac50f9665e4b28" 
    allowfullscreen 
    frameborder="0"
    class="video"> </iframe></p>
</div>
<div style="margin-bottom:5px">
<strong> <a href="https://speakerdeck.com/jeffgoldsmith/p8105-cross-validation" title="Cross validation" target="_blank">Cross Validation</a> </strong> from <strong><a href="https://speakerdeck.com/jeffgoldsmith" target="_blank">Jeff Goldsmith</a></strong>.
</div>
<p><br></p>
<hr />
</div>
<div id="video-lecture" class="section level3">
<h3>Video Lecture</h3>
<div class="vid_container">
<p><iframe 
    src="https://www.youtube.com/embed/nOIp6J8Uas4"
    frameborder="0" allowfullscreen class="video"> </iframe></p>
</div>
<hr />
</div>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>I’ll write code for today’s content in a new R Markdown document called <code>cross_validation.Rmd</code> in the <code>linear_models</code> directory / repo. The code chunk below loads the usual packages (plus <code>mgcv</code>) and sets a seed for reproducibility.</p>
<pre class="r"><code>library(tidyverse)
library(modelr)
library(mgcv)</code></pre>
<pre><code>## Loading required package: nlme</code></pre>
<pre><code>## 
## Attaching package: &#39;nlme&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     collapse</code></pre>
<pre><code>## This is mgcv 1.8-31. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.</code></pre>
<pre class="r"><code>set.seed(1)</code></pre>
<div id="cv-by-hand" class="section level3">
<h3>CV “by hand”</h3>
<p>We’ll start with a simulated example. The code chunk below generates data under a non-linear model; I like to use this setting because “model complexity” is easiest for me to understand when I can see it.</p>
<pre class="r"><code>nonlin_df = 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
  )

nonlin_df %&gt;% 
  ggplot(aes(x = x, y = y)) + 
  geom_point()</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-3-1.png" width="90%" /></p>
<p>I’ll split this data into training and test sets (using <code>anti_join</code>!!), and replot showing the split. Our goal will be to use the training data (in black) to build candidate models, and then see how those models predict in the testing data (in red).</p>
<pre class="r"><code>train_df = sample_n(nonlin_df, 80)
test_df = anti_join(nonlin_df, train_df, by = &quot;id&quot;)

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() + 
  geom_point(data = test_df, color = &quot;red&quot;)</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-4-1.png" width="90%" /></p>
<p>I’ll fit three three models to the training data. Throughout, I’m going to use <code>mgcv::gam</code> for non-linear models – this is my go-to package for “additive models”, and I much prefer it to e.g. polynomial models. For today, you don’t have to know what this means, how <code>gam</code> works, or why I prefer it – just know that we’re putting smooth lines through data clouds, and we can control how smooth we want the fit to be.</p>
<p>The three models below have very different levels of complexity and aren’t nested, so testing approaches for nested model don’t apply.</p>
<pre class="r"><code>linear_mod = lm(y ~ x, data = train_df)
smooth_mod = mgcv::gam(y ~ s(x), data = train_df)
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)</code></pre>
<p>To understand what these models have done, I’ll plot the two <code>gam</code> fits.</p>
<pre class="r"><code>train_df %&gt;% 
  add_predictions(smooth_mod) %&gt;% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = &quot;red&quot;)</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-6-1.png" width="90%" /></p>
<pre class="r"><code>train_df %&gt;% 
  add_predictions(wiggly_mod) %&gt;% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = &quot;red&quot;)</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-6-2.png" width="90%" /></p>
<p>In a case like this, I can also use the handy <code>modelr::gather_predictions</code> function – this is, essentially, a short way of adding predictions for several models to a data frame and then “pivoting” so the result is a tidy, “long” dataset that’s easily plottable.</p>
<pre class="r"><code>train_df %&gt;% 
  gather_predictions(linear_mod, smooth_mod, wiggly_mod) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_line(aes(y = pred), color = &quot;red&quot;) + 
  facet_wrap(~model)</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-7-1.png" width="90%" /></p>
<p>A quick visual inspection suggests that the linear model is too simple, the standard <code>gam</code> fit is pretty good, and the wiggly <code>gam</code> fit is too complex. Put differently, the linear model is too simple and, no matter what training data we use, will never capture the true relationship between variables – it will be consistently wrong due to its simplicity, and is therefore biased. The wiggly fit, on the other hand, is chasing data points and will change a lot from one training dataset to the the next – it will be consistently wrong due to its complexity, and is therefore highly variable. Both are bad!</p>
<p>As a next step in my CV procedure, I’ll compute root mean squared errors (RMSEs) for each model.</p>
<pre class="r"><code>rmse(linear_mod, test_df)</code></pre>
<pre><code>## [1] 0.7052956</code></pre>
<pre class="r"><code>rmse(smooth_mod, test_df)</code></pre>
<pre><code>## [1] 0.2221774</code></pre>
<pre class="r"><code>rmse(wiggly_mod, test_df)</code></pre>
<pre><code>## [1] 0.289051</code></pre>
<p>The <code>modelr</code> has other outcome measures – RMSE is the most common, but median absolute deviation is pretty common as well.</p>
<p>The RMSEs are suggestive that both nonlinear models work better than the linear model, and that the smooth fit is better than the wiggly fit. However, to get a sense of model stability we really need to iterate this whole process. Of course, this could be done using loops but that’s a hassle …</p>
</div>
<div id="cv-using-modelr" class="section level3">
<h3>CV using <code>modelr</code></h3>
<p>Luckily, <code>modelr</code> has tools to automate elements of the CV process. In particular, <code>crossv_mc</code> preforms the training / testing split multiple times, a stores the datasets using list columns.</p>
<pre class="r"><code>cv_df = 
  crossv_mc(nonlin_df, 100) </code></pre>
<p><code>crossv_mc</code> tries to be smart about memory – rather than repeating the dataset a bunch of times, it saves the data once and stores the indexes for each training / testing split using a <code>resample</code> object. This can be coerced to a dataframe, and can often be treated exactly like a dataframe. However, it’s not compatible with <code>gam</code>, so we have to convert each training and testing dataset (and lose that nice memory-saving stuff in the process) using the code below. It’s worth noting, though, that if all the models you want to fit use <code>lm</code>, you can skip this.</p>
<pre class="r"><code>cv_df %&gt;% pull(train) %&gt;% .[[1]] %&gt;% as_tibble</code></pre>
<pre><code>## # A tibble: 79 x 3
##       id      x       y
##    &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1     1 0.266   1.11  
##  2     2 0.372   0.764 
##  3     3 0.573   0.358 
##  4     4 0.908  -3.04  
##  5     6 0.898  -1.99  
##  6     7 0.945  -3.27  
##  7     8 0.661  -0.615 
##  8     9 0.629   0.0878
##  9    10 0.0618  0.392 
## 10    11 0.206   1.63  
## # … with 69 more rows</code></pre>
<pre class="r"><code>cv_df %&gt;% pull(test) %&gt;% .[[1]] %&gt;% as_tibble</code></pre>
<pre><code>## # A tibble: 21 x 3
##       id      x      y
##    &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1     5 0.202   1.33 
##  2    12 0.177   0.836
##  3    19 0.380   0.982
##  4    22 0.212   0.710
##  5    28 0.382   0.932
##  6    31 0.482   0.498
##  7    37 0.794  -1.12 
##  8    42 0.647   0.158
##  9    47 0.0233 -0.148
## 10    56 0.0995  1.13 
## # … with 11 more rows</code></pre>
<pre class="r"><code>cv_df =
  cv_df %&gt;% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))</code></pre>
<p>I now have many training and testing datasets, and I’d like to fit my candidate models above and assess prediction accuracy as I did for the single training / testing split. To do this, I’ll fit models and obtain RMSEs using <code>mutate</code> + <code>map</code> &amp; <code>map2</code>.</p>
<pre class="r"><code>cv_df = 
  cv_df %&gt;% 
  mutate(
    linear_mod  = map(train, ~lm(y ~ x, data = .x)),
    smooth_mod  = map(train, ~mgcv::gam(y ~ s(x), data = .x)),
    wiggly_mod  = map(train, ~gam(y ~ s(x, k = 30), sp = 10e-6, data = .x))) %&gt;% 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)),
    rmse_wiggly = map2_dbl(wiggly_mod, test, ~rmse(model = .x, data = .y)))</code></pre>
<p>I’m mostly focused on RMSE as a way to compare these models, and the plot below shows the distribution of RMSE values for each candidate model.</p>
<pre class="r"><code>cv_df %&gt;% 
  select(starts_with(&quot;rmse&quot;)) %&gt;% 
  pivot_longer(
    everything(),
    names_to = &quot;model&quot;, 
    values_to = &quot;rmse&quot;,
    names_prefix = &quot;rmse_&quot;) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-12-1.png" width="90%" /></p>
<p>Repeating the split is helpful – now we get a sense of variance in prediction error and can compare prediction error distributions across methods. The smooth fit is a clear winner!</p>
<p>It’s worth remembering, though, that this isn’t testing a null hypothesis and there aren’t p-values as a result.</p>
</div>
<div id="example-child-growth" class="section level3">
<h3>Example: Child Growth</h3>
<p>We’ll take a quick look at an example involving real data and more realistic candidate model. A cross-sectional study of Nepalese children was carried out to understand the relationships between various measures of growth, including weight and arm circumference. You can download the data <a href="./data/nepalese_children.csv">here</a>; the code chunk below imports the data and plots the variables we’ll focus on.</p>
<pre class="r"><code>child_growth = read_csv(&quot;./data/nepalese_children.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   age = col_double(),
##   sex = col_double(),
##   weight = col_double(),
##   height = col_double(),
##   armc = col_double()
## )</code></pre>
<pre class="r"><code>child_growth %&gt;% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5)</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-13-1.png" width="90%" /></p>
<p>The plots suggests some non-linearity, especially at the low end of the weight distribution. We’ll try three models: a linear fit; a piecewise linear fit; and a smooth fit using <code>gam</code>. For the piecewise linear fit, we need to add a “change point term” to our dataframe. (Like additive models, for now it’s not critical that you understand everything about a piecewise linear fit – we’ll see a plot of the results soon, and the intuition from that is enough for our purposes.)</p>
<pre class="r"><code>child_growth =
  child_growth %&gt;% 
  mutate(weight_cp = (weight &gt; 7) * (weight - 7))</code></pre>
<p>The code chunk below fits each of the candidate models to the full dataset. The piecewise linear model is nested in the linear model and could be assessed using statistical significance, but the smooth model is not nested in anything else. (Also, comparing a piecewise model with a changepoint at 7 to a piecewise model with a changepoint at 8 would be a non-nested comparison…)</p>
<pre class="r"><code>linear_mod = lm(armc ~ weight, data = child_growth)
pwl_mod    = lm(armc ~ weight + weight_cp, data = child_growth)
smooth_mod = gam(armc ~ s(weight), data = child_growth)</code></pre>
<p>As before, I’ll plot the three models to get intuition for goodness of fit.</p>
<pre class="r"><code>child_growth %&gt;% 
  gather_predictions(linear_mod, pwl_mod, smooth_mod) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = &quot;red&quot;) + 
  facet_grid(~model)</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-16-1.png" width="90%" /></p>
<p>It’s not clear which is best – the linear model is <em>maybe</em> too simple, but the piecewise and non-linear models are pretty similar! Better check prediction errors using the same process as before – again, since I want to fit a <code>gam</code> model, I have to convert the <code>resample</code> objects produced by <code>crossv_mc</code> to dataframes, but wouldn’t have to do this if I only wanted to compare the linear and piecewise models.</p>
<pre class="r"><code>cv_df =
  crossv_mc(child_growth, 100) %&gt;% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))</code></pre>
<p>Next I’ll use <code>mutate</code> + <code>map</code> &amp; <code>map2</code> to fit models to training data and obtain corresponding RMSEs for the testing data.</p>
<pre class="r"><code>cv_df = 
  cv_df %&gt;% 
  mutate(
    linear_mod  = map(train, ~lm(armc ~ weight, data = .x)),
    pwl_mod     = map(train, ~lm(armc ~ weight + weight_cp, data = .x)),
    smooth_mod  = map(train, ~gam(armc ~ s(weight), data = as_tibble(.x)))) %&gt;% 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
    rmse_pwl    = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)))</code></pre>
<p>Finally, I’ll plot the prediction error distribution for each candidate model.</p>
<pre class="r"><code>cv_df %&gt;% 
  select(starts_with(&quot;rmse&quot;)) %&gt;% 
  pivot_longer(
    everything(),
    names_to = &quot;model&quot;, 
    values_to = &quot;rmse&quot;,
    names_prefix = &quot;rmse_&quot;) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()</code></pre>
<p><img src="cross_validation_files/figure-html/unnamed-chunk-19-1.png" width="90%" /></p>
<p>Based on these results, there’s clearly some improvement in predictive accuracy gained by allowing non-linearity – whether this is sufficient to justify a more complex model isn’t obvious, though. Among the non-linear models, the smooth fit from <code>gam</code> <em>might</em> be a bit better than the piecewise linear model. Which candidate model is best, though, depends a bit on the need to balance complexity with goodness of fit and interpretability. In the end, I’d probably go with the piecewise linear model – the non-linearity is clear enough that it should be accounted for, and the differences between the piecewise and <code>gam</code> fits are small enough that the easy interpretation of the piecewise model “wins”.</p>
</div>
</div>
<div id="other-materials" class="section level2">
<h2>Other materials</h2>
<p>Cross validation is important, but still a bit new to the tidyverse. Some helpful posts are available, though, including:</p>
<ul>
<li>This <a href="https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom">post</a> has a pretty detailed analysis of K fold CV</li>
<li><a href="http://rpubs.com/dgrtwo/cv-modelr">This</a> is a shorter, somewhat more dated example</li>
</ul>
<p>The Introduction to Statistical Learning with R isn’t free online, but if you can track it down Chapter 5 has some useful material as well.</p>
<p>The code that I produced working examples in lecture is <a href="https://github.com/P8105/linear_models">here</a>.</p>
</div>

<br><br>
<footer>
  <img src="images/p8105_stickers.png" alt="stickers" style="width:30%">
  <br>
  <p class="copyright text-muted" align="center">Copyright &copy; 2019 Jeff Goldsmith</p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
